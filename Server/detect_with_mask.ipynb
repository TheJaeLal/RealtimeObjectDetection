{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(config.mask_model_infer_path,mode='rb') as graph_file:\n",
    "        serialized_graph = graph_file.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = utils.get_class_map(config.class_map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_names = utils.get_dir_images(config.test_imgs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reframe_box_masks_to_image_masks(box_masks, boxes, image_height,\n",
    "                                     image_width):\n",
    "    \n",
    "    \"\"\"Transforms the box masks back to full image masks.\n",
    "    Embeds masks in bounding boxes of larger masks whose shapes correspond to\n",
    "    image shape.\n",
    "    Args:\n",
    "    box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width].\n",
    "    boxes: A tf.float32 tensor of size [num_masks, 4] containing the box\n",
    "           corners. Row i contains [ymin, xmin, ymax, xmax] of the box\n",
    "           corresponding to mask i. Note that the box corners are in\n",
    "           normalized coordinates.\n",
    "    image_height: Image height. The output mask will have the same height as\n",
    "                  the image height.\n",
    "    image_width: Image width. The output mask will have the same width as the\n",
    "                 image width.\n",
    "    Returns:\n",
    "    A tf.float32 tensor of size [num_masks, image_height, image_width].\n",
    "    \"\"\"\n",
    "  \n",
    "    # TODO(rathodv): Make this a public function.\n",
    "    def reframe_box_masks_to_image_masks_default():\n",
    "        \n",
    "        \"\"\"The default function when there are more than 0 box masks.\"\"\"\n",
    "        \n",
    "        def transform_boxes_relative_to_boxes(boxes, reference_boxes):\n",
    "            boxes = tf.reshape(boxes, [-1, 2, 2])\n",
    "            min_corner = tf.expand_dims(reference_boxes[:, 0:2], 1)\n",
    "            max_corner = tf.expand_dims(reference_boxes[:, 2:4], 1)\n",
    "            transformed_boxes = (boxes - min_corner) / (max_corner - min_corner)\n",
    "            return tf.reshape(transformed_boxes, [-1, 4])\n",
    "\n",
    "        box_masks_expanded = tf.expand_dims(box_masks, axis=3)\n",
    "        num_boxes = tf.shape(box_masks_expanded)[0]\n",
    "        unit_boxes = tf.concat(\n",
    "            [tf.zeros([num_boxes, 2]), tf.ones([num_boxes, 2])], axis=1)\n",
    "        reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes, boxes)\n",
    "    \n",
    "        return tf.image.crop_and_resize(\n",
    "            image=box_masks_expanded,\n",
    "            boxes=reverse_boxes,\n",
    "            box_ind=tf.range(num_boxes),\n",
    "            crop_size=[image_height, image_width],\n",
    "            extrapolation_value=0.0)\n",
    "    \n",
    "    image_masks = tf.cond(\n",
    "      tf.shape(box_masks)[0] > 0,\n",
    "      reframe_box_masks_to_image_masks_default,\n",
    "      lambda: tf.zeros([0, image_height, image_width, 1], dtype=tf.float32))\n",
    "    \n",
    "    return tf.squeeze(image_masks, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph = detection_graph) as sess:\n",
    "    \n",
    "    for img_name in img_names:\n",
    "       \n",
    "        img_path = os.path.join(config.test_imgs_dir,img_name)\n",
    "        test_img = utils.load_image(img_path)\n",
    "        \n",
    "        input_ = sess.graph.get_tensor_by_name(\"import/image_tensor:0\")\n",
    "        boxes = sess.graph.get_tensor_by_name(\"import/detection_boxes:0\")\n",
    "        scores = sess.graph.get_tensor_by_name(\"import/detection_scores:0\")\n",
    "        classes = sess.graph.get_tensor_by_name(\"import/detection_classes:0\")\n",
    "        masks = sess.graph.get_tensor_by_name(\"import/detection_masks:0\")\n",
    "        num_detections = sess.graph.get_tensor_by_name(\"import/num_detections:0\")\n",
    "    \n",
    "        #masks = reframe_box_masks_to_image_masks(masks[0],boxes[0],test_img.shape[0],test_img.shape[1])\n",
    "        \n",
    "        (boxes, scores, classes, masks, num_detections) = sess.run([boxes,scores,\n",
    "                                                                  classes,masks,\n",
    "                                                                  num_detections],\n",
    "                                                                  feed_dict = {\n",
    "                                                                      input_:test_img\n",
    "                                                                  }\n",
    "                                                                ) \n",
    "        boxes = np.squeeze(boxes,axis=0)\n",
    "        scores = np.squeeze(scores,axis=0)\n",
    "        classes = np.squeeze(classes,axis=0)\n",
    "        masks = np.squeeze(masks,axis=0)\n",
    "        test_img = np.squeeze(test_img,axis=0)\n",
    "\n",
    "        detections = utils.get_detections(scores,config.threshold_score)\n",
    "\n",
    "        utils.draw_bounding_box(test_img,detections,boxes,classes,class_map,masks)\n",
    "         \n",
    "        save_path = os.path.join(config.result_imgs_dir,img_name)\n",
    "        \n",
    "        utils.save_image(save_path,test_img)\n",
    "        \n",
    "        #print(img_name,test_img.shape,masks.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
